{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ye/user/yejg/SW_DATA/Or/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import random\n",
    "import os,sys\n",
    "import datetime\n",
    "\n",
    "from model import ResNetModel\n",
    "sys.path.insert(0, '../utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageData:\n",
    "\n",
    "    def __init__(self, batch_size, load_size, channels, augment_flag,num_class):\n",
    "        self.batch_size = batch_size\n",
    "        self.load_size = load_size\n",
    "        self.channels = channels\n",
    "        self.augment_flag = augment_flag\n",
    "        self.num_class=num_class\n",
    "        self.mean_color=tf.constant([132.2766, 139.6506, 146.9702],name=\"mean_color\")\n",
    "\n",
    "    def image_processing(self, filename,label):\n",
    "        x = tf.read_file(filename)\n",
    "        x_decode = tf.image.decode_jpeg(x, channels=self.channels)\n",
    "        img = tf.image.resize_images(x_decode, [self.load_size, self.load_size])\n",
    "        img = tf.cast(img, tf.float32) / 127.5 - 1\n",
    "\n",
    "        if self.augment_flag :\n",
    "            augment_size = self.load_size + (30 if self.load_size == 256 else 15)\n",
    "            p = random.random()\n",
    "            if p > 0.5:\n",
    "                img = augmentation(img, augment_size)\n",
    "                \n",
    "        lab=tf.cast(label,tf.int32)\n",
    "        lab=tf.one_hot(lab,num_class,dtype=tf.float32)\n",
    "        img=tf.subtract(img,self.mean_color)\n",
    "        return img,lab\n",
    "\n",
    "\n",
    "def augmentation(image, augment_size):\n",
    "    seed = random.randint(0, 2 ** 31 - 1)\n",
    "    ori_image_shape = tf.shape(image)\n",
    "    image = tf.image.random_flip_left_right(image, seed=seed)\n",
    "    image = tf.image.resize_images(image, [augment_size, augment_size])\n",
    "    image = tf.random_crop(image, ori_image_shape, seed=seed)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_float('learning_rate', 0.0001, 'Learning rate for adam optimizer')\n",
    "tf.app.flags.DEFINE_integer('resnet_depth', 101, 'ResNet architecture to be used: 50, 101 or 152')\n",
    "tf.app.flags.DEFINE_integer('num_epochs', 10, 'Number of epochs for training')\n",
    "tf.app.flags.DEFINE_integer('num_classes', 26, 'Number of classes')\n",
    "tf.app.flags.DEFINE_integer('batch_size', 128, 'Batch size')\n",
    "tf.app.flags.DEFINE_string('train_layers', 'fc', 'Finetuning layers, seperated by commas')\n",
    "\n",
    "tf.app.flags.DEFINE_string('training_file', '../data/train_origin.txt', 'Training dataset file')\n",
    "tf.app.flags.DEFINE_string('val_file', '../data/val.txt', 'Validation dataset file')\n",
    "tf.app.flags.DEFINE_string('tensorboard_root_dir', '../training', 'Root directory to put the training logs and weights')\n",
    "tf.app.flags.DEFINE_integer('log_step', 10, 'Logging period in terms of iteration')\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "img_size=224\n",
    "img_ch=3\n",
    "augment_flag=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_file=\"../data/val.txt\"\n",
    "#training_file=\"../data/train_origin.txt\"\n",
    "train_data=pd.read_csv(FLAGS.training_file,header=None,sep=\" \")\n",
    "train_images=[str(s) for s in train_data.iloc[:,0]]\n",
    "train_labels=[int(l) for l in train_data.iloc[:,1]]\n",
    "\n",
    "val_data=pd.read_csv(FLAGS.val_file,header=None,sep=\" \")\n",
    "val_images=[str(s) for s in val_data.iloc[:,0]]\n",
    "val_labels=[int(l) for l in val_data.iloc[:,1]]\n",
    "\n",
    "\n",
    "\n",
    "#mean_color=[132.2766, 139.6506, 146.9702]\n",
    "\n",
    "image=tf.placeholder(tf.string,shape=[None])\n",
    "label=tf.placeholder(tf.int32,shape=[None])\n",
    "batch_size=tf.placeholder(tf.int64)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, img_size,img_size,img_ch])\n",
    "y = tf.placeholder(tf.float32, [None,FLAGS.num_classes])\n",
    "is_training = tf.placeholder('bool', [])\n",
    "tra_num_batches=len(train_images)//FLAGS.batch_size\n",
    "val_num_batches=len(val_images)//FLAGS.batch_size\n",
    "#mean_color=tf.constant(mean_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    # Create training directories\n",
    "    now = datetime.datetime.now()\n",
    "    train_dir_name = now.strftime('resnet_%Y%m%d_%H%M%S')\n",
    "    train_dir = os.path.join(FLAGS.tensorboard_root_dir, train_dir_name)\n",
    "    checkpoint_dir = os.path.join(train_dir, 'checkpoint')\n",
    "    tensorboard_dir = os.path.join(train_dir, 'tensorboard')\n",
    "    tensorboard_train_dir = os.path.join(tensorboard_dir, 'train')\n",
    "    tensorboard_val_dir = os.path.join(tensorboard_dir, 'val')\n",
    "\n",
    "    if not os.path.isdir(FLAGS.tensorboard_root_dir): os.mkdir(FLAGS.tensorboard_root_dir)\n",
    "    if not os.path.isdir(train_dir): os.mkdir(train_dir)\n",
    "    if not os.path.isdir(checkpoint_dir): os.mkdir(checkpoint_dir)\n",
    "    if not os.path.isdir(tensorboard_dir): os.mkdir(tensorboard_dir)\n",
    "    if not os.path.isdir(tensorboard_train_dir): os.mkdir(tensorboard_train_dir)\n",
    "    if not os.path.isdir(tensorboard_val_dir): os.mkdir(tensorboard_val_dir)\n",
    "\n",
    "    # Write flags to txt\n",
    "    flags_file_path = os.path.join(train_dir, 'flags.txt')\n",
    "    flags_file = open(flags_file_path, 'w')\n",
    "    flags_file.write('learning_rate={}\\n'.format(FLAGS.learning_rate))\n",
    "    flags_file.write('resnet_depth={}\\n'.format(FLAGS.resnet_depth))\n",
    "    flags_file.write('num_epochs={}\\n'.format(FLAGS.num_epochs))\n",
    "    flags_file.write('batch_size={}\\n'.format(FLAGS.batch_size))\n",
    "    flags_file.write('train_layers={}\\n'.format(FLAGS.train_layers))\n",
    "\n",
    "    flags_file.write('tensorboard_root_dir={}\\n'.format(FLAGS.tensorboard_root_dir))\n",
    "    flags_file.write('log_step={}\\n'.format(FLAGS.log_step))\n",
    "    flags_file.close()\n",
    "    \n",
    "    tra_Image_Data_Class = ImageData(FLAGS.batch_size, img_size,img_ch,augment_flag,FLAGS.num_classes)\n",
    "    train_dataset=tf.data.Dataset.from_tensor_slices((train_images,train_labels))\n",
    "    train_dataset = train_dataset.map(tra_Image_Data_Class.image_processing, num_parallel_calls=8).shuffle(10000).prefetch(FLAGS.batch_size).batch(FLAGS.batch_size).repeat()\n",
    "\n",
    "    train_iterator=train_dataset.make_initializable_iterator()\n",
    "    tra_img,tra_lab=train_iterator.get_next()\n",
    "\n",
    "\n",
    "    val_Image_Data_Class = ImageData(FLAGS.batch_size, img_size,img_ch,False,FLAGS.num_classes)\n",
    "    val_dataset=tf.data.Dataset.from_tensor_slices((val_images,val_labels))\n",
    "    val_dataset = val_dataset.map(val_Image_Data_Class.image_processing, num_parallel_calls=8).shuffle(10000).prefetch(FLAGS.batch_size).batch(FLAGS.batch_size).repeat()\n",
    "\n",
    "    val_iterator=val_dataset.make_initializable_iterator()\n",
    "    val_img,val_lab=val_iterator.get_next()\n",
    "    \n",
    "    # Model\n",
    "    train_layers = train_layers.split(',')\n",
    "    model = ResNetModel(is_training, depth=FLAGS.resnet_depth, num_classes=FLAGS.num_classes)\n",
    "    loss = model.loss(x, y)\n",
    "    train_op = model.optimize(FLAGS.learning_rate, train_layers)\n",
    "\n",
    "    # Training accuracy of the model\n",
    "    correct_pred = tf.equal(tf.argmax(model.prob, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Summaries\n",
    "    tf.summary.scalar('train_loss', loss)\n",
    "    tf.summary.scalar('train_accuracy', accuracy)\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "\n",
    "    train_writer = tf.summary.FileWriter(tensorboard_train_dir)\n",
    "    val_writer = tf.summary.FileWriter(tensorboard_val_dir)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        train_writer.add_graph(sess.graph)\n",
    "\n",
    "        sess.run(train_iterator.initializer,feed_dict={image:train_images,label:train_labels,batch_size:FLAGS.batch_size})\n",
    "        # Load the pretrained weights\n",
    "        model.load_original_weights(sess, skip_layers=train_layers)\n",
    "\n",
    "        print(\"{} Start training...\".format(datetime.datetime.now()))\n",
    "        for epoch in range(FLAGS.num_epochs):\n",
    "            step=1\n",
    "            print(\"{} Epoch number: {}\".format(datetime.datetime.now(), epoch+1))\n",
    "            for idx in range(tra_num_batches):\n",
    "                batch_x,batch_y=sess.run([tra_img,tra_lab])\n",
    "\n",
    "                _,tra_loss,tra_acc=sess.run([train_op,loss,accuracy],feed_dict={x:batch_x,y:batch_y,is_training:True})\n",
    "\n",
    "                if step%log_step==0:\n",
    "                   #print(\"[ Epoch:%d ],Step:%d,** loss:%f,accuracy:%f **\"%(epoch,step,tra_loss,tra_acc))\n",
    "                   s = sess.run(merged_summary, feed_dict={x: batch_x, y: batch_y, is_training: False})\n",
    "                   train_writer.add_summary(s, epoch * train_batches_per_epoch + step)\n",
    "                step+=1\n",
    "\n",
    "            print(\"{} Start validation\".format(datetime.datetime.now()))\n",
    "            test_acc = 0.\n",
    "            test_count = 0\n",
    "\n",
    "            sess.run(val_iterator.initializer,feed_dict={image:val_images,label:val_labels,batch_size:FLAGS.batch_size})\n",
    "            for _ in range(val_num_batches):\n",
    "                batch_x,batch_y=sess.run([val_img,val_lab])\n",
    "                val_loss,val_acc=sess.run([loss,accuracy],feed_dict={x:batch_x,y:batch_y,is_training:False})\n",
    "\n",
    "                test_acc+=val_acc\n",
    "                test_count+=1\n",
    "\n",
    "            test_acc/=test_count\n",
    "            s = tf.Summary(value=[\n",
    "                    tf.Summary.Value(tag=\"validation_accuracy\", simple_value=test_acc)\n",
    "                ])\n",
    "            val_writer.add_summary(s, epoch+1)\n",
    "\n",
    "            print(\"{} Validation Accuracy = {:.4f}\".format(datetime.datetime.now(), test_acc))\n",
    "\n",
    "            print(\"{} Saving checkpoint of model...\".format(datetime.datetime.now()))\n",
    "            #save checkpoint of the model\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'model_epoch'+str(epoch+1)+'.ckpt')\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            print(\"{} Model checkpoint saved at {}\".format(datetime.datetime.now(), checkpoint_path))\n",
    "\n",
    "\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tra_Image_Data_Class = ImageData(FLAGS.batch_size, img_size,img_ch,augment_flag,FLAGS.num_classes)\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((train_images,train_labels))\n",
    "train_dataset = train_dataset.map(tra_Image_Data_Class.image_processing, num_parallel_calls=8).shuffle(10000).prefetch(FLAGS.batch_size).batch(FLAGS.batch_size).repeat()\n",
    "\n",
    "train_iterator=train_dataset.make_initializable_iterator()\n",
    "tra_img,tra_lab=train_iterator.get_next()\n",
    "\n",
    "\n",
    "val_Image_Data_Class = ImageData(FLAGS.batch_size, img_size,img_ch,False,FLAGS.num_classes)\n",
    "val_dataset=tf.data.Dataset.from_tensor_slices((val_images,val_labels))\n",
    "val_dataset = val_dataset.map(val_Image_Data_Class.image_processing, num_parallel_calls=8).shuffle(10000).prefetch(FLAGS.batch_size).batch(FLAGS.batch_size).repeat()\n",
    "\n",
    "val_iterator=val_dataset.make_initializable_iterator()\n",
    "val_img,val_lab=val_iterator.get_next()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(iterator.initializer,feed_dict={image:images,label:labels,batch_size:BATCH_SIZE})\n",
    "    batch_x,batch_y=sess.run([img,lab])\n",
    "    print(batch_x.shape,batch_y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Model\n",
    "train_layers = train_layers.split(',')\n",
    "model = ResNetModel(is_training, depth=FLAGS.resnet_depth, num_classes=FLAGS.num_classes)\n",
    "loss = model.loss(x, y)\n",
    "train_op = model.optimize(FLAGS.learning_rate, train_layers)\n",
    "\n",
    "# Training accuracy of the model\n",
    "correct_pred = tf.equal(tf.argmax(model.prob, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Summaries\n",
    "tf.summary.scalar('train_loss', loss)\n",
    "tf.summary.scalar('train_accuracy', accuracy)\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "train_writer = tf.summary.FileWriter(tensorboard_train_dir)\n",
    "val_writer = tf.summary.FileWriter(tensorboard_val_dir)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer.add_graph(sess.graph)\n",
    "    \n",
    "    sess.run(train_iterator.initializer,feed_dict={image:train_images,label:train_labels,batch_size:FLAGS.batch_size})\n",
    "    # Load the pretrained weights\n",
    "    model.load_original_weights(sess, skip_layers=train_layers)\n",
    "    \n",
    "    print(\"{} Start training...\".format(datetime.datetime.now()))\n",
    "    for epoch in range(FLAGS.num_epochs):\n",
    "        step=1\n",
    "        print(\"{} Epoch number: {}\".format(datetime.datetime.now(), epoch+1))\n",
    "        for idx in range(tra_num_batches):\n",
    "            batch_x,batch_y=sess.run([tra_img,tra_lab])\n",
    "\n",
    "            _,tra_loss,tra_acc=sess.run([train_op,loss,accuracy],feed_dict={x:batch_x,y:batch_y,is_training:True})\n",
    "            \n",
    "            if step%log_step==0:\n",
    "               #print(\"[ Epoch:%d ],Step:%d,** loss:%f,accuracy:%f **\"%(epoch,step,tra_loss,tra_acc))\n",
    "               s = sess.run(merged_summary, feed_dict={x: batch_x, y: batch_y, is_training: False})\n",
    "               train_writer.add_summary(s, epoch * train_batches_per_epoch + step)\n",
    "            step+=1\n",
    "        \n",
    "        print(\"{} Start validation\".format(datetime.datetime.now()))\n",
    "        test_acc = 0.\n",
    "        test_count = 0\n",
    "        \n",
    "        sess.run(val_iterator.initializer,feed_dict={image:val_images,label:val_labels,batch_size:FLAGS.batch_size})\n",
    "        for _ in range(val_num_batches):\n",
    "            batch_x,batch_y=sess.run([val_img,val_lab])\n",
    "            val_loss,val_acc=sess.run([loss,accuracy],feed_dict={x:batch_x,y:batch_y,is_training:False})\n",
    "            \n",
    "            test_acc+=val_acc\n",
    "            test_count+=1\n",
    "        \n",
    "        test_acc/=test_count\n",
    "        s = tf.Summary(value=[\n",
    "                tf.Summary.Value(tag=\"validation_accuracy\", simple_value=test_acc)\n",
    "            ])\n",
    "        val_writer.add_summary(s, epoch+1)\n",
    "        \n",
    "        print(\"{} Validation Accuracy = {:.4f}\".format(datetime.datetime.now(), test_acc))\n",
    "        \n",
    "        print(\"{} Saving checkpoint of model...\".format(datetime.datetime.now()))\n",
    "        #save checkpoint of the model\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, 'model_epoch'+str(epoch+1)+'.ckpt')\n",
    "        save_path = saver.save(sess, checkpoint_path)\n",
    "        print(\"{} Model checkpoint saved at {}\".format(datetime.datetime.now(), checkpoint_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
