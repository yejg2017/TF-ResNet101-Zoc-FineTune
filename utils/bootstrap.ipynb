{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import pandas as pd\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n",
    "from collections import  Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "class BatchPreprocessor(object):\n",
    "\n",
    "    def __init__(self, dataset_file_path, num_classes, output_size=[227, 227], horizontal_flip=False, shuffle=False,\n",
    "                 mean_color=[132.2766, 139.6506, 146.9702], multi_scale=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.output_size = output_size\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.shuffle = shuffle\n",
    "        self.mean_color = mean_color\n",
    "        self.multi_scale = multi_scale\n",
    "\n",
    "        self.pointer = 0\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Read the dataset file\n",
    "        dataset_file = open(dataset_file_path)\n",
    "        lines = dataset_file.readlines()\n",
    "        for line in lines:\n",
    "            items = line.split()\n",
    "            self.images.append(items[0])\n",
    "            self.labels.append(int(items[1]))\n",
    "\n",
    "        # Shuffle the data\n",
    "        if self.shuffle:\n",
    "            self.shuffle_data()\n",
    "\n",
    "    def shuffle_data(self):\n",
    "        images = self.images[:]\n",
    "        labels = self.labels[:]\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        idx = np.random.permutation(len(labels))\n",
    "        for i in idx:\n",
    "            self.images.append(images[i])\n",
    "            self.labels.append(labels[i])\n",
    "\n",
    "    def reset_pointer(self):\n",
    "        self.pointer = 0\n",
    "\n",
    "        if self.shuffle:\n",
    "            self.shuffle_data()\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        # Get next batch of image (path) and labels\n",
    "        paths = self.images[self.pointer:(self.pointer+batch_size)]\n",
    "        labels = self.labels[self.pointer:(self.pointer+batch_size)]\n",
    "\n",
    "        # Update pointer\n",
    "        self.pointer += batch_size\n",
    "\n",
    "        # Read images\n",
    "        images = np.ndarray([batch_size, self.output_size[0], self.output_size[1], 3])\n",
    "        for i in range(len(paths)):\n",
    "            img = cv2.imread(paths[i])\n",
    "\n",
    "            # Flip image at random if flag is selected\n",
    "            if self.horizontal_flip and np.random.random() < 0.5:\n",
    "                img = cv2.flip(img, 1)\n",
    "\n",
    "            if self.multi_scale is None:\n",
    "                # Resize the image for output\n",
    "                img = cv2.resize(img, (self.output_size[0], self.output_size[0]))\n",
    "                img = img.astype(np.float32)\n",
    "            elif isinstance(self.multi_scale, list):\n",
    "                # Resize to random scale\n",
    "                new_size = np.random.randint(self.multi_scale[0], self.multi_scale[1], 1)[0]\n",
    "                img = cv2.resize(img, (new_size, new_size))\n",
    "                img = img.astype(np.float32)\n",
    "\n",
    "                # random crop at output size\n",
    "                diff_size = new_size - self.output_size[0]\n",
    "                random_offset_x = np.random.randint(0, diff_size, 1)[0]\n",
    "                random_offset_y = np.random.randint(0, diff_size, 1)[0]\n",
    "                img = img[random_offset_x:(random_offset_x+self.output_size[0]),\n",
    "                          random_offset_y:(random_offset_y+self.output_size[0])]\n",
    "\n",
    "            # Subtract mean color\n",
    "            img -= np.array(self.mean_color)\n",
    "\n",
    "            images[i] = img\n",
    "\n",
    "        # Expand labels to one hot encoding\n",
    "        one_hot_labels = np.zeros((batch_size, self.num_classes))\n",
    "        for i in range(len(labels)):\n",
    "            one_hot_labels[i][labels[i]] = 1\n",
    "\n",
    "        # Return array of images and labels\n",
    "        return images, one_hot_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机抽样样本来训练，验证迁移学习的性能---找到一个比较好的训练子集，模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27208908 2.87909836 1.334283   7.96033994 9.77391304] \n",
      " {0: 20655, 2: 4212, 1: 1952, 4: 575, 3: 706}\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_table(\"../data/train_orgin.txt\",header=None,sep=\" \")\n",
    "labels=[int(lab) for lab  in train.iloc[:,1]]\n",
    "weights=class_weight.compute_class_weight(class_weight=\"balanced\",classes=np.unique(labels),y=labels)\n",
    "print(weights,\"\\n\",dict(Counter(labels)))\n",
    "weights_dict={k:v for k,v in enumerate(weights)} \n",
    "\n",
    "X,y=np.array(train.iloc[:,0]),[int(i) for i in train.iloc[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def W_bootstrap(data,seed=1234,valid_ratio=0.2):\n",
    "    n_sample=data.shape[0]\n",
    "    n_valid=int(n_sample*valid_ratio)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    labels=[int(lab) for lab in data[:,1]]\n",
    "    images=[str(img) for img in data[:,0]]\n",
    "    weights=class_weight.compute_class_weight(class_weight=\"balanced\",\n",
    "                                              classes=np.unique(labels),\n",
    "                                              y=np.array(labels))\n",
    "    #weights=softmax(weights)\n",
    "    weights=weights/sum(weights)\n",
    "    \n",
    "    uniq_class=np.unique(labels)\n",
    "    train_labels=np.random.choice(uniq_class,p=weights,size=n_sample-n_valid)\n",
    "    valid_labels=np.random.choice(uniq_class,p=weights,size=n_valid)\n",
    "    return train_labels,valid_labels\n",
    "\n",
    "def softmax(weights):\n",
    "    weights=[np.exp(x) for x in weights]\n",
    "    return weights/sum(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
