{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the model using the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from model import ResNetModel\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, '../utils')\n",
    "from preprocessor import BatchPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageData:\n",
    "\n",
    "    def __init__(self, batch_size, load_size, channels, augment_flag,num_class):\n",
    "        self.batch_size = batch_size\n",
    "        self.load_size = load_size\n",
    "        self.channels = channels\n",
    "        self.augment_flag = augment_flag\n",
    "        self.num_class=num_class\n",
    "        self.mean_color=tf.constant([132.2766, 139.6506, 146.9702],name=\"mean_color\")\n",
    "\n",
    "    def image_processing(self, filename,label):\n",
    "        x = tf.read_file(filename)\n",
    "        x_decode = tf.image.decode_jpeg(x, channels=self.channels)\n",
    "        img = tf.image.resize_images(x_decode, [self.load_size, self.load_size])\n",
    "        img = tf.cast(img, tf.float32) #/ 127.5 - 1\n",
    "\n",
    "        if self.augment_flag :\n",
    "            augment_size = self.load_size + (30 if self.load_size == 256 else 15)\n",
    "            p = random.random()\n",
    "            if p > 0.5:\n",
    "                img = augmentation(img, augment_size)\n",
    "                \n",
    "        lab=tf.cast(label,tf.int32)\n",
    "        lab=tf.one_hot(lab,self.num_class,dtype=tf.float32)\n",
    "        #img=tf.subtract(img,self.mean_color)\n",
    "        return img,lab\n",
    "\n",
    "\n",
    "def augmentation(image, augment_size):\n",
    "    seed = random.randint(0, 2 ** 31 - 1)\n",
    "    ori_image_shape = tf.shape(image)\n",
    "    image = tf.image.random_flip_left_right(image, seed=seed)\n",
    "    image = tf.image.resize_images(image, [augment_size, augment_size])\n",
    "    image = tf.random_crop(image, ori_image_shape, seed=seed)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir=\"../training/resnet_20181022_150646/checkpoint\"\n",
    "#val_dir=\"/home/ye/user/yejg/database/Kaggle_Eye/Diabetes/grades/test\"\n",
    "val_dir=\"/home/ye/user/yejg/database/ZocEye/origin/\"\n",
    "batch_size=64\n",
    "num_classes=5\n",
    "\n",
    "model_path=tf.train.latest_checkpoint(checkpoint_dir=checkpoint_dir)\n",
    "val_file=\"../data/val.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load evaluate dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "image_list=[]\n",
    "label_list=[]\n",
    "\n",
    "#label_dict={\"Dr_0\":0,\"Dr_1\":1,\"Dr_2\":2,\"Dr_3\":3,\"Dr_4\":4}\n",
    "label_dict={\"health\":0,\"sick\":1}\n",
    "for s in os.listdir(val_dir):\n",
    "    sub_dir=os.path.join(val_dir,s)\n",
    "    for ss in os.listdir(sub_dir):\n",
    "        image_list.append(os.path.join(sub_dir,ss))\n",
    "        label_list.append(s)\n",
    "        \n",
    "label_list=[label_dict[k] for k in label_list]\n",
    "#val_ImageData=ImageData(augment_flag=False,batch_size=batch_size,load_size=224,num_class=num_classes,channels=3)\n",
    "val_num_batches=len(image_list)//batch_size"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "images=np.vstack([image_list,label_list])\n",
    "images=np.transpose(images)\n",
    "np.random.shuffle(images)\n",
    "\n",
    "images=pd.DataFrame(images)\n",
    "images.to_csv(\"../data/test.txt\",sep=\" \",header=None,index=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "val_dataset=tf.data.Dataset.from_tensor_slices((image_list,label_list))\n",
    "val_dataset=val_dataset.map(val_ImageData.image_processing,num_parallel_calls=8).shuffle(10000).prefetch(batch_size).batch(batch_size)\n",
    "val_iterator=val_dataset.make_initializable_iterator()\n",
    "val_img,val_lab=val_iterator.get_next()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_preprocessor = BatchPreprocessor(dataset_file_path=val_file, num_classes=num_classes, output_size=[224, 224])\n",
    "val_num_batches = np.floor(len(val_preprocessor.labels) / batch_size).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "x = tf.placeholder(tf.float32, [None,224, 224, 3])\n",
    "y = tf.placeholder(tf.float32, [None,num_classes])\n",
    "is_training = tf.placeholder('bool', [])\n",
    "\n",
    "\n",
    "# Model\n",
    "model = ResNetModel(is_training, depth=101, num_classes=num_classes)\n",
    "model.inference(x)\n",
    "# Training accuracy of the model\n",
    "correct_pred = tf.equal(tf.argmax(model.prob, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "prediction=tf.argmax(model.prob,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../training/resnet_20181022_150646/checkpoint/model_epoch100.ckpt\n",
      "2018-11-13 14:58:38.969899 Start validation\n",
      "2018-11-13 14:59:04.212095 Validation Accuracy = 0.9688\n",
      "2018-11-13 15:05:27.439315 Validation Accuracy = 0.9844\n",
      "2018-11-13 15:11:18.207774 Validation Accuracy = 0.8906\n",
      "2018-11-13 15:16:06.991086 Validation Accuracy = 0.9062\n",
      "2018-11-13 15:21:38.231008 Validation Accuracy = 0.8750\n",
      "2018-11-13 15:27:14.577092 Validation Accuracy = 0.8750\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    pred=[]\n",
    "    true=[]\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #sess.run(val_iterator.initializer)\n",
    "    saver.restore(sess=sess,save_path=model_path)\n",
    "    \n",
    "    print(\"{} Start validation\".format(datetime.datetime.now()))\n",
    "    for step in range(val_num_batches):\n",
    "        #batch_x,batch_y=sess.run([val_img,val_lab])\n",
    "        batch_x, batch_y = val_preprocessor.next_batch(batch_size)\n",
    "        val_acc,val_pred=sess.run([accuracy,prediction],feed_dict={x:batch_x,y:batch_y,is_training:False})\n",
    "        #val_pred=sess.run([accuracy,prediction],feed_dict={x:batch_x,y:batch_y,is_training:False})\n",
    "        true.append(batch_y[0])\n",
    "        pred.append(val_pred[0])\n",
    "        \n",
    "        if step%20==0:\n",
    "           print(\"{} Validation Accuracy = {:.4f}\".format(datetime.datetime.now(), val_acc))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
